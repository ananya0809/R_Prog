---
title: "Lab: Machine Learning + Trees"
author: "36-600"
output: 
  html_document:
    toc: no
    toc_float: no
    theme: spacelab
---

To answer the questions below, it will help you to refer to the class notes and to Sections 8.1 and 8.3.1-8.3.2 of ISLR 1ed. *Note, however, that we use the rpart package to create trees, which ISLR does not use.* So ISLR is best used for looking up background details.

# Regression Trees

## Data, Part I

We'll begin by importing the heart-disease dataset and log-transforming the response variable, `Cost`:
```{r}
df      <- read.csv("http://www.stat.cmu.edu/~pfreeman/heart_disease.csv",stringsAsFactors=TRUE)
df      <- df[,-10]
w       <- which(df$Cost > 0)
df      <- df[w,]
df$Cost <- log(df$Cost)
summary(df)
```

## Question 1

Split the data into training and test sets. Call these `df.train` and `df.test`. Reuse the random number seed that you used when splitting the data prior to learning the multiple linear regression model in a previous lab.
```{r}
# REPLACE ME WITH CODE
set.seed(101)  # Replace with your actual seed value
n <- nrow(df)
train_indices <- sample(1:n, size = 0.7 * n)  # 80% for training

df.train <- df[train_indices, ]
df.test <- df[-train_indices, ]

# Check the split
cat("Training set observations:", nrow(df.train), "\n")
cat("Test set observations:", nrow(df.test), "\n")

```

## Question 2

Learn a regression tree model and report the test-set MSE. How does this MSE compare with what you observed for the linear model? Is it lower? If so, then the (inherently more flexible) nonlinear regression tree model is adapting better to the geometry of the data than the (inherently less flexible) linear model...with the tradeoff that inferential ability is reduced. (But not eliminated, as we'll see.)
```{r}
# REPLACE ME WITH CODE
# install.packages("rpart")  # Uncomment if rpart isn't installed
library(rpart)

tree_model <- rpart(Cost ~ ., data = df.train, method = "anova")
predictions <- predict(tree_model, df.test)
mse <- mean((df.test$Cost - predictions)^2)
cat("Test-set MSE for regression tree:", mse, "\n")
```
```
Replace me with text
MSE from Lab 5 for Linear Model: 1.649642
MSE for regression tree: 1.361889 

MSE for regression tree is lower.
```

## Question 3

Visualize the tree. Install the package `rpart.plot` and run its namesake function while inputting the results of your tree fit. If you were of a mind to do inference, you'd look to see what variables lie at the top of the tree: these are presumably the ones with the most statistical information. (Note that because this is a regression tree, the `extra` argument to `rpart.plot()` won't be useful here and you can leave it out of the function call.)
```{r fig.align='center',fig.width=4,fig.height=4}
# REPLACE ME WITH CODE
# install.packages("rpart.plot")  # Uncomment if rpart.plot isn't installed
library(rpart.plot)
rpart.plot(tree_model)
```

## Question 4

Create a diagnostic plot, specifically, the test-set predicted responses ($y$-axis) versus the test-set observed responses ($x$-axis). The predictions were generated in Question 2. For enhanced readability, be sure to set the $x$ limits and the $y$ limits to be the same, and add a line of slope one to the plot. Does the plot seem strange to you? If so, and you don't know what is going on, call us over.
```{r fig.align='center',fig.height=4,fig.width=4}
# REPLACE ME WITH CODE
# Set up the plot with same limits for x and y axes
plot(df.test$Cost, predictions,
     xlab = "Observed Cost (Test Set)",
     ylab = "Predicted Cost (Test Set)",
     main = "Predicted vs Observed Cost",
     xlim = range(df.test$Cost),
     ylim = range(df.test$Cost))

# Add a 45-degree line for reference
abline(a = 0, b = 1, col = "red", lwd = 2)
```

## Question 5

Run `plotcp()` with the output of your call to `rplot()` to see if the tree needs pruned. (Yes, it should be "needs to be pruned," but you're in Pittsburgh.) As a reminder, you are looking for the leftmost point that lies below the dotted line. If this is not the last point (the point farthest to the right), then `plotcp()` is trying to tell you to prune the tree. Note that depending on how you split the data, you may or may not see evidence that pruning is necessary.

Note that even if pruning is deemed necessary, you do not need to do that pruning here. You would, if necessary, go back to the code given in today's notes to extract the pruned tree, which you can then use to, e.g., compute an MSE.
```{r fig.align='center',fig.width=4,fig.height=4}
# REPLACE ME WITH CODE
plotcp(tree_model)
```

---

# Classification Trees

Now we turn our attention to classification trees.

## Data, Part II

We will now load in the data on political movements that you looked at in the logistic regression lab:
```{r}
load(url("http://www.stat.cmu.edu/~pfreeman/movement.Rdata"))
f <- function(variable,level0="NO",level1="YES") {
  n               <- length(variable)
  new.variable    <- rep(level0,n)
  w               <- which(variable==1)
  new.variable[w] <- level1
  return(factor(new.variable))
}
predictors$nonviol      <- f(predictors$nonviol)
predictors$sanctions    <- f(predictors$sanctions)
predictors$aid          <- f(predictors$aid)
predictors$support      <- f(predictors$support)
predictors$viol.repress <- f(predictors$viol.repress)
predictors$defect       <- f(predictors$defect)
levels(response)        <- c("FAILURE","SUCCESS")
df           <- cbind(predictors,response)
names(df)[9] <- "label"
rm(id.half,id,predictors.half,predictors,response)
```

## Question 6

Split the data! If you can, match what you did in the logistic regression lab (as far as seed-setting is concerned).
```{r}
# REPLACE ME WITH CODE
set.seed(123)
n <- nrow(df)
train_indices <- sample(1:n, size = 0.7 * n)

df.train <- df[train_indices, ]
df.test <- df[-train_indices, ]

# Check the split
cat("Training set observations:", nrow(df.train), "\n")
cat("Test set observations:", nrow(df.test), "\n")
```

## Question 7

Your next job is to learn a classification tree. Do that, and output a confusion matrix. (Note that the use of the `predict()` function might be, for you, a little different here: use `type="class"` as an argument, so that the output is not a probability but a classification. You can use the output directly when creating the confusion matrix.) What is the misclassification rate? (If you split your data in the same manner as you did for linear regression, is the MCR lower? Just make a mental note.)
```{r}
# REPLACE ME WITH CODE
library(rpart)
class_tree <- rpart(label ~ ., data = df.train, method = "class")
predictions <- predict(class_tree, df.test, type = "class")
table(Predicted = predictions, Actual = df.test$label)
confusion_matrix <- table(Predicted = predictions, Actual = df.test$label)
misclassification_rate <- 1 - sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Misclassification Rate:", misclassification_rate, "\n")


```
```
Replace me with text
Misclassification Rate: 0.3787879
```

## Question 8

Let's compute the Area Under Curve (AUC) for the decision tree model. Dealing with prediction is a bit tricky as the argument change a bit from model to model, but what you'd want to do here is run

- resp.pred <- predict(rpart.out,newdata=df.test,type="prob")[,2]

and then mimic the material presented in the notes to generate an AUC.
```{r}
# REPLACE ME WITH CODE
# install.packages("pROC")  # Uncomment if pROC is not installed
library(pROC)
# Assuming class_tree is the fitted model from the previous step
resp.pred <- predict(class_tree, newdata = df.test, type = "prob")[, 2]
# Create an AUC object comparing predicted probabilities to actual labels
auc <- roc(df.test$label, resp.pred, levels = c("FAILURE", "SUCCESS"))

# Display the AUC value
cat("AUC:", auc$auc, "\n")

# Optional: Plot the ROC curve
plot(auc, main = "ROC Curve for Decision Tree Model")

```

## Question 9

Plot your classification tree (perhaps with the argument `extra=104` or `extra=106`) and determine if pruning is necessary using `plotcp()`. Make a mental note about the pruning...but see Question 10.
```{r fig.align='center',fig.width=4,fig.height=4}
# REPLACE ME WITH CODE
library(rpart.plot)
rpart.plot(class_tree, extra = 104)  # or use extra = 106 for slightly different details
plotcp(class_tree)
```

## Question 10

Here, I suspect you saw clear evidence that pruning would be useful. Go ahead, prune the tree and replot the pruned tree. Also, compute the misclassification rate: did pruning make things worse?
```{r fig.align='center',fig.width=4,fig.height=4}
# REPLACE ME WITH CODE
printcp(class_tree)
optimal_cp <- class_tree$cptable[which.min(class_tree$cptable[, "xerror"]), "CP"]
cat("Optimal CP:", optimal_cp, "\n")
pruned_tree <- prune(class_tree, cp = optimal_cp)
rpart.plot(pruned_tree, extra = 104)  # or extra = 106
# Make predictions with the pruned tree
pruned_predictions <- predict(pruned_tree, df.test, type = "class")
pruned_confusion_matrix <- table(Predicted = pruned_predictions, Actual = df.test$label)

# Calculate the misclassification rate
pruned_misclassification_rate <- 1 - sum(diag(pruned_confusion_matrix)) / sum(pruned_confusion_matrix)
cat("Misclassification Rate after pruning:", pruned_misclassification_rate, "\n")

```
```
Replace me with text
Misclassification Rate after pruning: 0.3636364 
Misclassification Rate before pruning: 0.3787879 

It looks like pruning the tree slightly improved the misclassification rate, reducing it from 0.378 to 0.364. This suggests that pruning successfully reduced some overfitting, making the model more generalizable to new data without compromising predictive performance.
```
